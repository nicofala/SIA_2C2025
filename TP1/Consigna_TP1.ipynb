{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **TP1 - Sistemas de Inteligencia Artificial**\n",
        "## Regresión con Modelos Lineales\n",
        "#### Dataset: Properati Bs. As. 2020 ([Kaggle](https://www.kaggle.com/datasets/alejandromendivil/bsas-realstate-on-sale/))"
      ],
      "metadata": {
        "id": "ar0OrNjHXxBY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " **Trabjaremos con modelos lineales**\n",
        "\n",
        "Son aquellos que tienen la forma:\n",
        "\n",
        "$\\hat{y} =\\theta_0 +\\theta_1 x_1 + \\theta_2 x_2 + .. +\\theta_n x_n$\n",
        "\n",
        "o, vectorialmente\n",
        "\n",
        "$\\hat{y} = \\vec{\\theta} \\cdot \\vec{x}$\n",
        "\n",
        "donde $\\hat{y}$ es la predicción,\n",
        "$n$ es el número de _features_ o variables predictoras, $x_i$ es el i-ésimo feature y $\\vec{\\theta}$ es el vector de parámetros o _pesos_ del modelo (lo que entrenamos).\n",
        "\n",
        "**Modelos lineales regularizados**\n",
        "\n",
        "En los modelos lineales simples, los parámetros $\\theta_i$ se ajustan minimizando el error cuadrático medio entre las predicciones y los valores reales. Sin embargo, cuando hay **muchas variables**, correlaciones fuertes entre ellas o riesgo de *overfitting*, se utilizan **términos de regularización** que penalizan la magnitud de los coeficientes, mejorando así la capacidad de generalización del modelo.\n",
        "\n",
        "Algunos ejemplos:\n",
        "\n",
        "- **Ridge Regression** (*L2 regularization*):  \n",
        "\n",
        "  $\\text{Loss} = \\text{MSE} + \\alpha \\sum_{i=1}^n \\theta_i^2$\n",
        "\n",
        "  Tiende a mantener todos los coeficientes pequeños pero distintos de cero.\n",
        "\n",
        "- **Lasso Regression** (*L1 regularization*):  \n",
        "\n",
        "  $\\text{Loss} = \\text{MSE} + \\alpha \\sum_{i=1}^n |\\theta_i|$\n",
        "\n",
        "  Puede forzar coeficientes exactamente a cero, funcionando también como método de selección de variables.\n",
        "\n",
        "- **Elastic Net**: combina L1 y L2, balanceando sus ventajas.\n",
        "\n",
        "\n",
        "**Modelos lineales con *features* polinomiales**\n",
        "\n",
        "Los modelos lineales pueden extenderse para capturar relaciones **no lineales** entre las variables de entrada y la variable objetivo mediante la creación de nuevas variables que son **combinaciones polinomiales** de las originales.\n",
        "\n",
        "Por ejemplo, con dos variables $x_1$ y $x_2$ y un polinomio de grado 2, el modelo considera:  \n",
        "$\n",
        "\\hat{y} = \\theta_0 + \\theta_1 x_1 + \\theta_2 x_2 + \\theta_3 x_1^2 + \\theta_4 x_2^2 + \\theta_5 x_1 x_2\n",
        "$  \n",
        "\n",
        "Aunque la relación entre las *features* y $\\hat{y}$ puede ser no lineal, el modelo sigue siendo **lineal en los parámetros** $\\theta_i$, por lo que conserva las propiedades y métodos de ajuste de los modelos lineales clásicos.\n",
        "\n",
        "Este enfoque, combinado con regularización, permite capturar patrones complejos sin perder el control sobre el sobreajuste.\n"
      ],
      "metadata": {
        "id": "PR6qqvp0bQKi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "------------------------\n",
        "------------------------\n",
        "**Instrucciones:**\n",
        "\n",
        "- **No** modificar las celdas de texto.\n",
        "\n",
        "- Resolver cada consigna en su sección correspondiente. Pueden sumar celdas de código y texto si lo consideran necesario. Recuerden que lo más importante es el razonamiento y la justificación de los pasos para demostrar comprensión del problema a resolver.\n",
        "\n",
        "- **ENTREGA:** Ir a Archivo > Descargar .ipynb. Este archivo .ipynb deberán subirlo al campus junto con las diapositivas en formato PDF (archivo no editable) hasta las 23:59hs del día anterior a la presentación. La presentación oral de este último documento será de manera grupal en hasta 10 minutos el día 08/09 durante el horario de clase (se sorteará el orden de los grupos al azar). Dado el tiempo de exposición, recomendamos un máximo de 5 diapositivas.\n",
        "\n",
        "------------------------\n",
        "------------------------"
      ],
      "metadata": {
        "id": "-R6wwoFId1jR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Importar librerías"
      ],
      "metadata": {
        "id": "-V-5zTHAY4La"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# las librerías escenciales\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "5VIEttouXxXN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Definir el problema"
      ],
      "metadata": {
        "id": "-mtIk-oScuSP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **¿Cuál es la tarea que queremos hacer con aprendizaje automático?**\n",
        "  - Predecir el precio de las propiedades.\n",
        "- **¿Qué métrica de evaluación vamos a usar?**\n",
        "  - Utilizaremos el RMSE (_root mean squared error_).\n"
      ],
      "metadata": {
        "id": "D_m3C8pWdFlD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Cargar los datos"
      ],
      "metadata": {
        "id": "_nLzaARXdIdt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargamos el dataset de Kaggle\n",
        "import kagglehub\n",
        "import os\n",
        "\n",
        "path = kagglehub.dataset_download(\"alejandromendivil/bsas-realstate-on-sale\")\n",
        "csv_file_path = os.path.join(path, 'bsas_realstate_on_sale_properati_dataset_2020.csv')\n",
        "\n",
        "df = pd.read_csv(csv_file_path) # lo guardamos en un DataFrame de pandas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6HyJhR9LdNSB",
        "outputId": "8ecb6e9f-8a3c-4bce-b32a-d82d31acca01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/alejandromendivil/bsas-realstate-on-sale?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 43.9M/43.9M [00:00<00:00, 189MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4.  Análisis exploratorio de datos"
      ],
      "metadata": {
        "id": "-33bC1AId4-b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Acá comienzan ustedes..\n",
        "- 4.1) **Conocer los datos**\n",
        "  - Explorar la estructura del dataset: cantidad de columnas y filas, tipos de datos, entender qué significa cada variable (métodos relevantes: `head()`, `info()`, `describe()`).\n",
        "\n",
        "- 4.2) **Valores faltantes**\n",
        "  - Calcular el porcentaje de valores nulos por columna.\n",
        "  - Decidir si se imputan, se eliminan o se dejan según la estrategia de preprocesamiento.\n",
        "\n",
        "- 4.3) **Distribuciones de variables y valores atípicos**\n",
        "  - Graficar histogramas, boxplots o violinplots para variables numéricas.\n",
        "  - Identificar valores atípicos y limpiarlos de ser necesario.\n",
        "  - Graficar conteos para variables categóricas (sug: `value_counts()` o `sns.countplot()`).\n",
        "\n",
        "- 4.4) **Relaciones entre variables**\n",
        "  - Graficar diagramas de dispersión entre variables relevantes y el precio (sug: `scatterplot()`, `sns.pairplot()`).\n",
        "  - Calcular matriz de correlación y visualizar (sug: `imshow` o `sns.heatmap()`)."
      ],
      "metadata": {
        "id": "eREonyRRIGCo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# su código"
      ],
      "metadata": {
        "id": "Rtiwz5_Zd8jQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Preparar los datos para modelos de ML"
      ],
      "metadata": {
        "id": "bDlGyz5Zd-EW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 5.1) **Selección de variables**\n",
        "  - Identificar variables numéricas y categóricas.\n",
        "  - Identificar si hay columnas irrelevantes o redundantes.\n",
        "  - Opcional: Aplicar ingeniería de features (ej: transformaciones o nuevas variables a partir de las presentes).\n",
        "  - Seleccionar un conjunto prometedor de variables predictoras.\n",
        "\n",
        "- 5.2) **Codificación de variables categóricas**\n",
        "  - Usar `OneHotEncoder` o `OrdinalEncoder`  para variables categóricas (decidir cual).\n",
        "\n",
        "- 5.3) **Imputación de valores faltantes**\n",
        "  - Imputar valores faltantes si hay. Decidir qué estrategia de imputación usar para variables numéricas y para categóricas (sug: `SimpleImputer`).\n",
        "\n",
        "- 5.4) **Separación de datos**\n",
        "  - Crear los conjuntos de entrenamiento y testeo `X_train`, `X_test`, `y_train`, `y_test` (sug: `train_test_split`).\n",
        "\n",
        "- 5.5) **Escalado de variables numéricas**\n",
        "  - Normalizar las variables numéricas (sug: `StandardScaler`).\n"
      ],
      "metadata": {
        "id": "PJA87tpUIoYo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# su código"
      ],
      "metadata": {
        "id": "jGvow7oOeF7p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Entrenamiento"
      ],
      "metadata": {
        "id": "pHVNB3HJeHKg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- 6.1) **Probar al menos 4 modelos distintos**\n",
        "  - Ej: Regresión lineal simple (`LinearRegression`), Ridge Regression (`Ridge`), Lasso Regression (`Lasso`).\n",
        "  - Probar modelos con regresión polinomial usando `PolynomialFeatures`.\n",
        "  - Ir siempre de lo más simple a lo más complejo.\n",
        "\n",
        "- 6.2) **Evaluar y comparar**\n",
        "  - Evaluar los modelos **solo** en el conjunto de entrenamiento mediante validación cruzada usando `cross_val_score`."
      ],
      "metadata": {
        "id": "qEtgIoP7JFZH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# su código"
      ],
      "metadata": {
        "id": "OhhsVyDGeqRS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. Ajuste fino\n",
        "\n"
      ],
      "metadata": {
        "id": "P29S1OwFgFVx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 7.1) **Buscar los mejores hiperparámetros**\n",
        "  - Para los modelos con hiperparámetros (como `alpha`  y/o `degree`), hacer un ajuste fino por validación cruzada (sug: `GridSearch` o `RandomizedSearch`).\n",
        "  - Elegir el modelo final basandose en las métricas de validación cruzada. Hacer un gráfico de barras comparando el RMSE de validación de los modelos comparados.\n",
        "  - Especificar cuál es el modelo elegido, sus hiperparámetros y variables de entrada (*features*)."
      ],
      "metadata": {
        "id": "tlEhRU6lVlp0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# su código"
      ],
      "metadata": {
        "id": "-TdyQOrdgKas"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8. Testeo"
      ],
      "metadata": {
        "id": "3ulTbqiVgNlR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 8.1) **Finalmente, evaluar el modelo final en el conjunto de testeo**\n",
        "  - Calcular el RMSE del modelo final (en test) y visualizar predicciones vs valores reales en un scatterplot.\n",
        "  - ¿Cuáles fueron las features más importantes?, ¿Pueden hacer alguna interpretación?"
      ],
      "metadata": {
        "id": "5V5q5IIWV6zo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# su código"
      ],
      "metadata": {
        "id": "TCAM9xgHgXuM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}